---
title: "ST5227_DataMining"
author: "Zhu Xu"
date: "Sem2"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##1. Linear Regression Model

fit model
$$
Y=\beta_0+\beta_1X_1+\beta_2X_2+\beta_3X_3+\beta_4X_4+\beta_5X_5+\epsilon
$$
```{r}
# lm
# pre
xy = read.table('/Users/xuzhu/Desktop/Notes/Sem2/ST5227-Applied_Data_Mining/01A/data01A.dat')
x1 = xy[,2]
x2 = xy[,3]
x3 = xy[,4]
x4 = xy[,5]
x5 = xy[,6]
y <- xy[,7]

reg <- lm(y~x1+x2+x3+x4+x5)
summary(reg)

new_x = read.table('/Users/xuzhu/Desktop/Notes/Sem2/ST5227-Applied_Data_Mining/01A/data01B.dat')
pre_data_1 = data.frame(x1=new_x[,2], 
                      x2=new_x[,3], x3=new_x[,4],
                      x4=new_x[,5], x5=new_x[,6])
predicted <- predict(reg, newdata=pre_data_1, 
                     interval="confidence", level = 0.95)
predicted 
```

##2. Confidence band

```{r}
data_2 = read.table('/Users/xuzhu/Desktop/Notes/Sem2/ST5227-Applied_Data_Mining/01A/data01C.dat')
x = data_2[,1]
y = data_2[,2]

reg_2 = lm(y~x)
newx = seq(min(x), max(x), 0.1)
pred <- predict(reg_2, newdata=data.frame(x=newx), 
                interval="confidence", level = 0.95) 
plot(x, y)
abline(reg_2, lwd=2)
lines(newx, pred[,2], lty=3, col='red', lwd=2)
lines(newx, pred[,3], lty=3, col='red', lwd=2)
title(main='Estimated regression function and its 95% confidence band')
```


```{r}
# Centralized
data = read.table('/Users/xuzhu/Desktop/Notes/Sem2/ST5227-Applied_Data_Mining/01A/data01C.dat')
x = data[,1]
y = data[,2]
# centralized
x_centralized = x-mean(x)
y_centralized = y-mean(y)

reg = lm(y_centralized~x_centralized-1)   #please note the -1 in the bracket

newx = seq(min(x_centralized), max(x_centralized), 0.1)
data_new = data.frame(x_centralized=newx)
pred <- predict(reg, newdata=data_new, 
                interval="confidence", level = 0.95) 

plot(x_centralized, y_centralized)
abline(reg, lwd=2)
lines(newx, pred[,2], lty=5, col='red', lwd=5)
lines(newx, pred[,3], lty=5, col='red', lwd=5)

title(main='Estimated regression function and its 95% confidence band')

# or

plot(x_centralized, y_centralized)
xx = c(newx, rev(newx))
yy = c(pred[,2], rev(pred[,3]))
polygon(xx, yy, col="gray")
abline(reg, lwd=2)
points(x_centralized, y_centralized)
title(main='Estimated regression function and its 95% confidence band')
```

```{r}
# To see the contribution of each predictor on Y_centralized
library(gam)
xy = read.table('/Users/xuzhu/Desktop/Notes/Sem2/ST5227-Applied_Data_Mining/01A/data01A.dat')
x1 = xy[,2]
x2 = xy[,3]
x3 = xy[,4]
x4 = xy[,5]
x5 = xy[,6]
y = xy[,7]

reg = gam(y~x1+x2+x3+x4+x5)
par(mfrow = c(2, 3))
plot(reg, se = TRUE)
```

```{r}
# LASSO
library(glmnet)

```


```{r}
#02B

#02Ba
library(glmnet)
mydata = read.csv('/Users/xuzhu/Desktop/Notes/Sem2/ST5227-Applied_Data_Mining/02B/diabetes.csv')

X = data.matrix(mydata[,1:10])
y = data.matrix(mydata[,11])

apply(X, 2, mean)
apply(X, 2, sd)

mean(y)
sd(y)

X = scale(X)     # you dont have to do it, the pacakge will do it for you
y = scale(y)
 
reg0 = glmnet(X, y, standardize=TRUE)

par(mfrow = c(1, 2))

plot(reg0)

mycv = cv.glmnet(X, y, nfolds=10, standardize=TRUE)

plot(mycv)

BestLambda = lambda=mycv$lambda.min
reg1 = glmnet(X, y, intercept=TRUE, lambda=BestLambda)

reg1$beta


```

```{r}
xy = read.table('/Users/xuzhu/Desktop/Notes/Sem2/ST5227-Applied_Data_Mining/02B/DMleukemia1.dat')
xy = data.matrix(xy)


y = xy[,251]
y = (y>0) - (y<=0)   # redefine the value of the classes 
x = xy[,1:250]

library(glmnet)

r0 = glmnet(x,y)
plot(r0)

mycv = cv.glmnet(x,y, nfolds = 5)
plot(mycv)

BestLambda = mycv$lambda.min

BestLambda

BestLambda = 0.1276111

reg = glmnet(x,y,lambda=BestLambda)

reg$beta


######## model validation for a new data set

xyNEW = read.table('/Users/xuzhu/Desktop/Notes/Sem2/ST5227-Applied_Data_Mining/02B/DMleukemia2.dat')
xyNEW = data.matrix(xyNEW)
xNEW = xyNEW[,1:250]
ypredict = predict(reg, type='response',newx = xNEW)

yNEW = xyNEW[,251]
yNEW = (yNEW>0) - (yNEW<=0)
n = length(yNEW)

errorLasso = mean((yNEW-ypredict)^2)
errorLasso

# classification error

yclassified = (ypredict>0)- (ypredict<=0)
ClassficationError = mean(yNEW != yclassified)

ClassficationError

plot(ypredict, yNEW, pch = 20, ylab='classes', xlab='predicted values')
points(ypredict, yclassified, col='red', pch=2) 
legend(-1, 0.9, pch=20, "true")
legend(-1, 0.4, pch=2, "classified", col='red')
```









